{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg4pcm/iF983sRsrdQNS4b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liangli217/LLM_learning/blob/main/Agents_with_OpenAI_SDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://drive.google.com/uc?export=view&id=1oCldVicFepwdYbPHcD8Ui4VeyQVJYgut\" height=\"400\"><center>"
      ],
      "metadata": {
        "id": "X1WvNLd4b5ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-agents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lHj-KCSfce91",
        "outputId": "ea7aadfa-5499-40be-d90f-850f8523b55b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-agents\n",
            "  Downloading openai_agents-0.3.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
            "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.15.0)\n",
            "Requirement already satisfied: openai<2,>=1.107.1 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.109.1)\n",
            "Requirement already satisfied: pydantic<3,>=2.10 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
            "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.15.0)\n",
            "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.11.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
            "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.37.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2,>=1.107.1->openai-agents) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.10->openai-agents) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.3.0)\n",
            "Downloading openai_agents-0.3.3-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
            "Successfully installed colorama-0.4.6 griffe-1.14.0 openai-agents-0.3.3 types-requests-2.32.4.20250913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from typing import List, Optional, Dict\n",
        "from dataclasses import dataclass\n",
        "from agents import Agent, Runner, function_tool\n",
        "import time, random, json"
      ],
      "metadata": {
        "id": "jo2bUVzPc1OJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "#Proper client initialization\n",
        "client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "GnOb23oQcsir"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-4o\"\n",
        "user_prompt =\"What's the best performing ETF?\""
      ],
      "metadata": {
        "id": "7Ac7ObO2vcjh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseLLM :\n",
        "\n",
        "  def __init__(self, model ):\n",
        "    self.model = model\n",
        "\n",
        "  def generate(self, user_prompt:str, max_tokens = 1000):\n",
        "\n",
        "    print(\"BaseLLM: making single API call...\")\n",
        "    start_time = time.time()\n",
        "    response = client.responses.create(\n",
        "        model=self.model,\n",
        "\n",
        "        input =[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "    end_time = time.time()\n",
        "\n",
        "    return {\n",
        "        \"content\": response.output_text,\n",
        "        \"tokens_used\": response.usage.total_tokens,\n",
        "        \"response_time\": end_time - start_time\n",
        "    }"
      ],
      "metadata": {
        "id": "XmCo7wzYvnpb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_llm = BaseLLM(model)\n",
        "llm_result = base_llm.generate(user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4Pwf9U3w-wL",
        "outputId": "7d52ef8f-14c7-4fa7-a92c-cfe51aa0f198"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseLLM: making single API call...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BASE LLM:\",model)\n",
        "print(\"=\"*50)\n",
        "print(f\"Response:\")\n",
        "print(llm_result['content'])\n",
        "print(f\"Tokens: {llm_result['tokens_used']}, Time: {llm_result['response_time']:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFka53_Hx8XP",
        "outputId": "88d5cb6c-8a44-42ac-b04e-b18980ae9f74"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BASE LLM: gpt-4o\n",
            "==================================================\n",
            "Response:\n",
            "Determining the \"best\" performing ETF can depend on the specific time frame, market conditions, and what you're looking to achieve. Some ETFs may be top performers in the short term but may not be suitable for long-term investments. Common performance metrics include total return over specific periods or performance compared to a benchmark index.\n",
            "\n",
            "To find the current best-performing ETF, you would typically look at financial news websites or platforms like Morningstar, Bloomberg, or Yahoo Finance. They often have updated lists and reports on ETFs that are currently outperforming others. Remember, past performance doesn't guarantee future results, and it's important to consider factors like fees, investment strategy, and risk when evaluating an ETF.\n",
            "Tokens: 149, Time: 6.94s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"gpt-5\"\n",
        "user_prompt =\"What's the best performing ETF (US only), provide top 3 for the best performance in the YTD?\""
      ],
      "metadata": {
        "id": "HY6vfuWuyR2R"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_llm = BaseLLM(model)\n",
        "llm_result = base_llm.generate(user_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "curPdeqhyTAV",
        "outputId": "09237b3b-8dca-41b1-bd53-c1b62eedd89f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseLLM: making single API call...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"BASE LLM:\",model)\n",
        "print(\"=\"*50)\n",
        "print(f\"Response:\")\n",
        "print(llm_result['content'])\n",
        "print(f\"Tokens: {llm_result['tokens_used']}, Time: {llm_result['response_time']:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEY89ZDayX0y",
        "outputId": "1d34ff9d-df2f-46a9-d3b1-8bdab50c3180"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "BASE LLM: gpt-5\n",
            "==================================================\n",
            "Response:\n",
            "A couple of quick clarifications so I can give you the right “top 3”:\n",
            "\n",
            "- Should I include leveraged/inverse ETFs (e.g., 2x, 3x), single‑stock ETFs, and ETNs? These often dominate YTD leaderboards.\n",
            "- Do you want price return or total return (includes dividends)?\n",
            "- Use last market close as of today, or a specific date?\n",
            "- Any minimum AUM or liquidity screen (e.g., >$50M AUM)?\n",
            "\n",
            "If you don’t specify, I’ll default to:\n",
            "- US-listed ETFs only, exclude ETNs, single-stock, and leveraged/inverse products\n",
            "- Total return YTD\n",
            "- As of last market close\n",
            "- Minimum AUM $50M\n",
            "\n",
            "Confirm these and I’ll provide the top 3 with tickers, names, and YTD returns.\n",
            "Tokens: 1104, Time: 16.24s\n"
          ]
        }
      ]
    }
  ]
}